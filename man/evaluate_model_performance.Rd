% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-12-train.R
\name{evaluate_model_performance}
\alias{evaluate_model_performance}
\title{Evaluate Model Performance Metrics}
\usage{
evaluate_model_performance(
  data,
  model_result,
  group_col = "group",
  custom_cutoff = NULL
)
}
\arguments{
\item{data}{A data frame containing the test data with both features and target variable}

\item{model_result}{Either a single trained model object or a list of trained models}

\item{group_col}{Name of the target variable column (default: "group")}

\item{custom_cutoff}{Optional custom probability cutoff (overrides use_youden if provided)}

\item{use_youden}{Logical indicating whether to use Youden's J statistic to determine optimal cutoff (default: FALSE)}
}
\value{
A data frame containing performance metrics for each model. For multiple models,
returns a combined data frame with one row per model.
}
\description{
This function evaluates the performance of one or more classification models using
various metrics including sensitivity, specificity, accuracy, AUC, etc. It supports
both single model evaluation and multiple model comparison.
}
\examples{
\dontrun{
# Example with single model
model <- train(...)  # trained model
test_data <- data.frame(...)  # test data
performance <- evaluate_model_performance(
  data = test_data,
  model_result = model,
  use_youden = TRUE
)

# Example with multiple models
model_list <- list(
  model1 = train(...),
  model2 = train(...)
)
performance <- evaluate_model_performance(
  data = test_data,
  model_result = model_list,
  custom_cutoff = 0.4
)
}
}
