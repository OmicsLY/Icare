% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-18-Validation-performannce.R
\name{ModelValidationPerformance}
\alias{ModelValidationPerformance}
\title{Evaluate Model Performance on Validation Dataset}
\usage{
ModelValidationPerformance(
  object,
  group_col = "group",
  palette_name = "AsteroidCity1",
  base_size = 14,
  save_plots = TRUE,
  save_dir = here("ModelData", "best_model_result"),
  plot_width = 5,
  plot_height = 5,
  alpha = 0.05,
  importance_threshold = 0.05,
  best_threshold = NULL,
  set_type = "validation"
)
}
\arguments{
\item{object}{A \code{Model_data} object containing training and validation datasets.}

\item{group_col}{Character. Name of the grouping variable (target). Default is "group".}

\item{palette_name}{Character. Color palette name for plots (from \code{wesanderson}). Default is "AsteroidCity1".}

\item{base_size}{Numeric. Base font size for plots. Default is 14.}

\item{save_plots}{Logical. Whether to save output plots. Default is TRUE.}

\item{save_dir}{Character. Directory path for saving plots. Default is \code{here("ModelData", "best_model_result")}.}

\item{plot_width}{Numeric. Plot width in inches. Default is 5.}

\item{plot_height}{Numeric. Plot height in inches. Default is 5.}

\item{alpha}{Numeric. Significance level for statistical tests. Default is 0.05.}

\item{importance_threshold}{Numeric. Threshold for variable importance (0-1). Default is 0.05.}

\item{best_threshold}{Numeric. Custom classification threshold. If NULL, uses model's optimal threshold.}
}
\value{
The input \code{Model_data} object with validation results added to the \code{best.model.result} slot.
}
\description{
This function validates a trained model's performance on a held-out validation dataset,
including ROC curve generation, performance metrics calculation, and variable importance checks.
It handles common validation issues like variable name mismatches and missing data imputation.
}
\section{Details}{

The function:
\itemize{
\item Verifies input data integrity
\item Handles variable name mismatches (e.g., factor dummy variables)
\item Imputes missing low-importance variables
\item Calculates performance metrics using \code{evaluate_model_performance()}
\item Generates ROC curves using \code{plot_validation_model_roc()}
}
}

\examples{
\dontrun{
model_data <- ModelValidationPerformance(model_data)
validation_results <- model_data@best.model.result$validation_result
}
}
