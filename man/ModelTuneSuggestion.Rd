% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-13-Tune.R
\name{ModelTuneSuggestion}
\alias{ModelTuneSuggestion}
\title{Generate and Evaluate Hyperparameter Tuning Suggestions}
\usage{
ModelTuneSuggestion(
  object,
  expand_factor = 1.5,
  suggestions = NULL,
  control = trainControl(method = "cv", number = 5),
  classProbs = TRUE,
  allowParallel = TRUE,
  group_col = "group",
  tune_grids = list(glm = NULL, rpart = expand.grid(cp = seq(1e-04, 0.01, length.out =
    10)), naive_bayes = NULL, bayesglm = NULL, rf = expand.grid(mtry = 1:5), xgbTree =
    expand.grid(nrounds = 100, max_depth = c(2, 4, 6), eta = c(0.01, 0.1), gamma = 0,
    colsample_bytree = 1, min_child_weight = 1, subsample = 1), svmRadial =
    expand.grid(sigma = 0.01, C = 2^(-1:2)), svmLinear = expand.grid(C = c(0.01, 0.1,
    1)), gbm = expand.grid(n.trees = c(50, 100), interaction.depth = c(2, 3), shrinkage =
    c(0.001, 0.01), n.minobsinnode = c(10, 
     20)), earth = expand.grid(degree = 1:2,
    nprune = 2:10), glmnet = expand.grid(alpha = c(0.1, 0.5, 0.9), lambda = 10^seq(-4,
    -1, 1)))
)
}
\arguments{
\item{object}{A Train_Model object containing the best model to tune}

\item{expand_factor}{Numeric factor to expand parameter ranges around current best values (default: 1.5)}

\item{suggestions}{Optional list of manual tuning suggestions (bypasses automatic generation)}

\item{control}{trainControl object specifying resampling method (default: 5-fold CV)}

\item{classProbs}{Logical indicating whether to compute class probabilities (default: TRUE)}

\item{allowParallel}{Logical indicating whether to allow parallel processing (default: TRUE)}

\item{group_col}{Name of the grouping variable column (default: "group")}

\item{tune_grids}{List of default tuning grids for reference ranges}
}
\value{
Returns the input Train_Model object with updated tuning results, or a list containing:
- model: The tuned model
- train_performance: Performance metrics on training data
- suggestions: The parameter grid used for tuning
}
\description{
This function generates intelligent hyperparameter tuning suggestions based on the best performing model
in a Train_Model object. It uses a combination of methods:
\enumerate{
\item For continuous parameters: Expands the search space around the current best values using logarithmic scaling
\item For discrete parameters: Explores neighboring integer values
\item For parameters with constraints: Ensures values stay within valid ranges
}
}
\details{
The function implements a "local search" strategy by focusing the parameter search around the current best values,
while expanding the range by a specified factor. This approach is more efficient than grid search when you have
a good starting point (the current best model).
}
\examples{
\dontrun{
# Manual tuning suggestions
custom_tune <- list(
  rf = expand.grid(mtry = c(3, 5, 7)),
  gbm = expand.grid(n.trees = c(100, 150), interaction.depth = c(3, 5))
)
object_model <- ModelTuneSuggestion(object_model, suggestions = custom_tune)
}
}
